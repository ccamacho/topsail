syntax = "proto3";
package caikit.runtime.Nlp;

import "generatedresult.proto";
import "caikit-nlp.proto";
import "caikit_data_model.generated.proto";

/* caikit.runtime.Nlp.TextGenerationTaskRequest */

message TextGenerationTaskRequest {
  string text = 1;
  oneof _preserve_input_text {
    bool preserve_input_text = 2;
  }
  oneof _max_new_tokens {
    int64 max_new_tokens = 3;
  }
  oneof _min_new_tokens {
    int64 min_new_tokens = 4;
  }
  oneof _truncate_input_tokens {
    int64 truncate_input_tokens = 5;
  }
  oneof _decoding_method {
    string decoding_method = 6;
  }
  oneof _top_k {
    int64 top_k = 7;
  }
  oneof _top_p {
    double top_p = 8;
  }
  oneof _typical_p {
    double typical_p = 9;
  }
  oneof _temperature {
    double temperature = 10;
  }
  oneof _seed {
    uint64 seed = 11;
  }
  oneof _repetition_penalty {
    double repetition_penalty = 12;
  }
  oneof _max_time {
    double max_time = 13;
  }
  oneof _exponential_decay_length_penalty {
    caikit_data_model.caikit_nlp.ExponentialDecayLengthPenalty exponential_decay_length_penalty = 14;
  }
  repeated string stop_sequences = 15;
}
/* caikit.runtime.Nlp.ServerStreamingTextGenerationTaskRequest */

message ServerStreamingTextGenerationTaskRequest {
  string text = 1;
  oneof _preserve_input_text {
    bool preserve_input_text = 2;
  }
  oneof _max_new_tokens {
    int64 max_new_tokens = 3;
  }
  oneof _min_new_tokens {
    int64 min_new_tokens = 4;
  }
  oneof _truncate_input_tokens {
    int64 truncate_input_tokens = 5;
  }
  oneof _decoding_method {
    string decoding_method = 6;
  }
  oneof _top_k {
    int64 top_k = 7;
  }
  oneof _top_p {
    double top_p = 8;
  }
  oneof _typical_p {
    double typical_p = 9;
  }
  oneof _temperature {
    double temperature = 10;
  }
  oneof _seed {
    uint64 seed = 11;
  }
  oneof _repetition_penalty {
    double repetition_penalty = 12;
  }
  oneof _max_time {
    double max_time = 13;
  }
  oneof _exponential_decay_length_penalty {
    caikit_data_model.caikit_nlp.ExponentialDecayLengthPenalty exponential_decay_length_penalty = 14;
  }
  repeated string stop_sequences = 15;
}
/* caikit.runtime.Nlp.BidiStreamingTokenClassificationTaskRequest */

message BidiStreamingTokenClassificationTaskRequest {
  string text_stream = 1;
  oneof _threshold {
    double threshold = 2;
  }
}
/* caikit_data_model.nlp.TokenClassificationResult */

message TokenClassificationResult {
  int64 start = 1;
  int64 end = 2;
  string word = 3;
  string entity = 4;
  string entity_group = 5;
  double score = 6;
  int64 token_count = 7;
}
/* .caikit_data_model.nlp.TokenClassificationStreamResult */

message TokenClassificationStreamResult {
  repeated caikit_data_model.nlp.TokenClassificationResult results = 1;
  int64 processed_index = 2;
}
/* caikit.runtime.Nlp.TextClassificationTaskRequest */

message TextClassificationTaskRequest {
  string text = 1;
}
/* caikit.runtime.Nlp.TokenClassificationTaskRequest */

message TokenClassificationTaskRequest {
  string text = 1;
  oneof _threshold {
    double threshold = 2;
  }
}
/* caikit.runtime.Nlp.NlpService */

service NlpService {
  rpc BidiStreamingTokenClassificationTaskPredict ( stream caikit.runtime.Nlp.BidiStreamingTokenClassificationTaskRequest ) returns ( stream caikit_data_model.nlp.TokenClassificationStreamResult );
  rpc ServerStreamingTextGenerationTaskPredict ( caikit.runtime.Nlp.ServerStreamingTextGenerationTaskRequest ) returns ( stream caikit_data_model.nlp.GeneratedTextStreamResult );
  rpc TextClassificationTaskPredict ( caikit.runtime.Nlp.TextClassificationTaskRequest ) returns ( caikit_data_model.nlp.ClassificationResults );
  rpc TextGenerationTaskPredict ( caikit.runtime.Nlp.TextGenerationTaskRequest ) returns ( caikit_data_model.nlp.GeneratedTextResult );
  rpc TokenClassificationTaskPredict ( caikit.runtime.Nlp.TokenClassificationTaskRequest ) returns ( caikit_data_model.nlp.TokenClassificationResults );
}
