---
- name: Get K8s api+machine name
  command: oc get nodes -lnode-role.kubernetes.io/worker -ojsonpath={.items[0].metadata.annotations[\'machine\\.openshift\\.io/machine\']}
  register: api_machinename_cmd
  failed_when: api_machinename_cmd.stdout | length == 0

- name: Get K8s machine name
  command: basename "{{ api_machinename_cmd.stdout }}"
  register: machinename_cmd

- name: Get AWS cluster name tag
  command:
    oc get machine/{{ machinename_cmd.stdout }}
       -n openshift-machine-api
       -ojsonpath={.spec.providerSpec.value.tags[?(@.value==\"owned\")].name}
  register: cluster_name_tag_cmd

- name: Get AWS cluster name
  command:
    basename "{{ cluster_name_tag_cmd.stdout }}"
  register: cluster_name_cmd

- name: Get AWS cluster region
  command:
    oc get machine/{{ machinename_cmd.stdout }}
       -n openshift-machine-api
       -ojsonpath={.spec.providerSpec.value.placement.region}
  register: cluster_region_cmd

- name: Store AWS cluster region in a variable
  set_fact:
    cluster_region: "{{ cluster_region_cmd.stdout }}"

- name: Print the cluster region
  command: echo "Cluster region is {{ cluster_region }}"

- name: Lookup the RDS db-instance ID
  shell:
    set -o pipefail;
    aws resourcegroupstaggingapi get-resources
         --resource-type-filters rds:db
         --tag-filters Key=integreatly.org/clusterID,Values={{ cluster_name_cmd.stdout }}
         --region "{{ cluster_region }}"
         --output json
        | jq -r .ResourceTagMappingList[0].ResourceARN | cut "-d:" -f7
  register: aws_rds_db_instance_id

- name: Remove the DB deletion protection
  command:
    aws rds modify-db-instance
        --db-instance-identifier "{{ aws_rds_db_instance_id.stdout }}"
        --no-deletion-protection
        --region "{{ cluster_region }}"

- name: Remove the DB instance without a final snapshot
  command:
    aws rds delete-db-instance
        --db-instance-identifier "{{ aws_rds_db_instance_id.stdout }}"
        --skip-final-snapshot
        --region "{{ cluster_region }}"

- name: Get the DB subnet group id
  shell:
    set -o pipefail;
    aws resourcegroupstaggingapi get-resources
         --resource-type-filters rds:subgrp
         --tag-filters Key=integreatly.org/clusterID,Values={{ cluster_name_cmd.stdout }}
         --region "{{ cluster_region }}"
         --output json
        | jq -r .ResourceTagMappingList[0].ResourceARN | cut "-d:" -f7
  register: aws_rds_db_subnet_group_id

- name: Remove the DB subnet group
  command:
    aws rds delete-db-subnet-group
        --db-subnet-group-name "{{ aws_rds_db_subnet_group_id.stdout }}"
        --region "{{ cluster_region }}"

- name: Use openshift-installer to delete the remaining resources
  block:
  - name: Prepare template variables
    set_fact:
      deletion_cluster_region: "{{ cluster_region }}"
      deletion_tag_identifier: integreatly.org/clusterID
      deletion_tag_value: "{{ cluster_name_cmd.stdout }}"

  - name: Create openshift-installer metadata.json
    template:
      src: "{{ rhods_cleanup_aws_metadata_json }}"
      dest: "{{ artifact_extra_logs_dir }}/metadata.json"
      mode: '0400'

  - name: Get the path of the openshift-installer
    when: not rhods_cleanup_aws_openshift_installer
    shell:
      set -o pipefail;
      ls subprojects/deploy-cluster/utils/installers/*/openshift-install | head -1
    register: openshift_installer_cmd

  - name: Trigger openshift-installer cluster deletion
    command: |
      {{ rhods_cleanup_aws_openshift_installer | default(openshift_installer_cmd) }} destroy cluster \
        --log-level=debug \
        --dir "{{ artifact_extra_logs_dir }}"
